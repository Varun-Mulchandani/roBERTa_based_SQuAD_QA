{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roBERTa_SQuAD_1.ipynb",
      "provenance": [],
      "mount_file_id": "180nmZwcBzuNlM1oqe5Tojx_JVeP6VdMj",
      "authorship_tag": "ABX9TyM09J+H8P26QIrHVtqhzULV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varun-Mulchandani/roBERTa_based_SQuAD_QA/blob/master/roBERTa_SQuAD_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYUgSYyy7bBN",
        "colab_type": "text"
      },
      "source": [
        "Confirming GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNdP3OR65Hbh",
        "colab_type": "code",
        "outputId": "d14f9dae-dde7-42de-dd60-5bac0c3b311f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stYUaQM07gmm",
        "colab_type": "text"
      },
      "source": [
        "For this project, I will be using HuggingFace's transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HswZUov85Vyh",
        "colab_type": "code",
        "outputId": "deb474b8-b1df-4b3e-aa94-c47457f1cd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOGCPDBz7mt_",
        "colab_type": "text"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5zlrgIl5i3q",
        "colab_type": "code",
        "outputId": "c5ed974a-2427-42be-dabe-2a805be31f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import *\n",
        "import tokenizers\n",
        "print('TF version', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version 2.2.0-rc4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcK0KYsh7qmN",
        "colab_type": "text"
      },
      "source": [
        "Max length for the input sequence is reduced to 384 due to lack of computaitonal resources for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDN0CKbE5ztn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 384\n",
        "\n",
        "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
        "    vocab_file = 'drive/My Drive/vocab-roberta-base.json',\n",
        "    merges_file = 'drive/My Drive/merges-roberta-base.txt',\n",
        "    lowercase = True,\n",
        "    add_prefix_space = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjXKqzG48KvL",
        "colab_type": "text"
      },
      "source": [
        "Loading the SQuAD dataset which has been converted to a csv file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r197F3Uo6fyx",
        "colab_type": "code",
        "outputId": "4f680659-9c32-4f88-ed3e-91b628da3c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "train = pd.read_csv('drive/My Drive/train (3).csv').fillna('')\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answers</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>269</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>207</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>2003</td>\n",
              "      <td>526</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>166</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Beyoncé</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            context\n",
              "0           0  ...  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "1           1  ...  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "2           2  ...  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "3           3  ...  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "4           4  ...  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7xIamCY6n82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rec = train.shape[0]  # Number of records in the training set\n",
        "inputs = np.ones((rec, MAX_LEN), dtype = 'int32') # Input vector\n",
        "attention_mask = np.zeros((rec, MAX_LEN), dtype = 'int32') # Attention Mask\n",
        "token_type_ids = np.zeros((rec, MAX_LEN), dtype = 'int32') # Tokens produced\n",
        "start_tokens = np.zeros((rec, MAX_LEN), dtype = 'int32') # Start logit for answer\n",
        "end_tokens = np.zeros((rec, MAX_LEN), dtype = 'int32') # End logit for answer\n",
        "\n",
        "for i in range(rec):\n",
        "\n",
        "  context = ' '+' '.join(train.loc[i, 'context'].split())\n",
        "  answer = ' '+' '.join(train.loc[i, 'answers'].split())\n",
        "  question = ' '+' '.join(train.loc[i, 'question'].split())\n",
        "\n",
        "  start_idx = train.loc[i, 'answer_start']\n",
        "\n",
        "  chars = np.zeros((len(context)))\n",
        "  chars[start_idx:start_idx + len(answer)] = 1\n",
        "  if context[start_idx - 1] == ' ':\n",
        "    chars[start_idx - 1] = 1\n",
        "  \n",
        "  enc1 = tokenizer.encode(context)\n",
        "  enc2 = tokenizer.encode(question)\n",
        "\n",
        "  # For resource limitations only.\n",
        "\n",
        "  if len(enc1) + len(enc2) + 4 < MAX_LEN:\n",
        "\n",
        "    #creating offsets\n",
        "    offsets = []\n",
        "    start_idx = 0\n",
        "\n",
        "    for t in enc1.ids:\n",
        "      w = tokenizer.decode([t])\n",
        "      offsets.append((start_idx, start_idx + len(w)))\n",
        "      start_idx += len(w)\n",
        "    \n",
        "    tokens = []\n",
        "    for j, (a, b) in enumerate(offsets):\n",
        "      sum_ = np.sum(chars[a:b])\n",
        "      if sum_ > 0:\n",
        "        tokens.append(j)\n",
        "\n",
        "    # The input for roberta is in the form <s> Question </s></s> Answer </s>\n",
        "    \n",
        "    inputs[i, :len(enc1.ids) + len(enc2.ids) + 4] = [0] + enc2.ids + [2,2] + enc1.ids + [2]\n",
        "\n",
        "    attention_mask[i, :len(enc1.ids) + len(enc2.ids) + 4] = 1\n",
        "\n",
        "    if len(tokens) > 0:\n",
        "      start_tokens[i, tokens[0] + 1] = 1\n",
        "      end_tokens[i, tokens[-1] + 1] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWJ6yUM3FxIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  ids = tf.keras.layers.Input((MAX_LEN,), dtype = tf.int32)\n",
        "  att = tf.keras.layers.Input((MAX_LEN,), dtype = tf.int32)\n",
        "  tok = tf.keras.layers.Input((MAX_LEN,), dtype = tf.int32)\n",
        "\n",
        "  config = RobertaConfig.from_pretrained('drive/My Drive/config-roberta-base.json')\n",
        "  bert_model = TFRobertaModel.from_pretrained('drive/My Drive/pretrained-roberta-base.h5', config = config)\n",
        "  x = bert_model(ids, attention_mask=att, token_type_ids = tok)\n",
        "\n",
        "  # For start logit\n",
        "\n",
        "  x1 = tf.keras.layers.Dropout(0.1)(x[0])\n",
        "  x1 = tf.keras.layers.Conv1D(1,1)(x1)\n",
        "  x1 = tf.keras.layers.Flatten()(x1)\n",
        "  x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "\n",
        "  # For end logit\n",
        "\n",
        "  x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "  x2 = tf.keras.layers.Conv1D(1,1)(x2)\n",
        "  x2 = tf.keras.layers.Flatten()(x2)\n",
        "  x2 = tf.keras.layers.Activation('softmax')(x2)\n",
        "\n",
        "  # Initalising the model\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = [ids, att, tok], outputs = [x1, x2])\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-5)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = optimizer)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE0rxYcoH5uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IeU7b3IH8mQ",
        "colab_type": "code",
        "outputId": "0b854b73-4683-48be-a692-4e2a520f3dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "history = model.fit([inputs, attention_mask, token_type_ids], [start_tokens, end_tokens], epochs = 3, batch_size = 4, validation_split = 0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "19535/19535 [==============================] - 4760s 244ms/step - loss: 5.7435 - activation_7_loss: 2.8490 - activation_8_loss: 2.8946 - val_loss: 3.8448 - val_activation_7_loss: 1.9756 - val_activation_8_loss: 1.8692\n",
            "Epoch 2/3\n",
            "19535/19535 [==============================] - 4756s 243ms/step - loss: 3.5832 - activation_7_loss: 1.8125 - activation_8_loss: 1.7707 - val_loss: 3.1420 - val_activation_7_loss: 1.5986 - val_activation_8_loss: 1.5434\n",
            "Epoch 3/3\n",
            "19535/19535 [==============================] - 4747s 243ms/step - loss: 2.8444 - activation_7_loss: 1.4487 - activation_8_loss: 1.3957 - val_loss: 2.7097 - val_activation_7_loss: 1.4078 - val_activation_8_loss: 1.3019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFyYqurIO-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}